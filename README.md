# Prediction with NonLinear Regression
 In this section, we will predict with NonLinear Regressions

<hr />

1. K-Nearest Neighbours(KNN)

  ðŸ“Œ Predictions are made based on observation similarity.

2. NonLinear Support Vector Regression(N-SVR)

  ðŸ“Œ The goal is to define the curve so that it can get the maximum point in the range of a margin with the smallest error.

3. Artificial Neural Network(ANN)

  ðŸ“Œ It is one of the powerful machine learning algorithms that can be used for classification and regression problems that refer to the way the human brain processes information.

4. Classification and Regression Trees(CART)

  ðŸ“Œ The aim is to transform the complex structures in the data set into simple decision structures. 

5. Bagged Trees

  ðŸ“Œ It is based on the evaluation of the predictions produced by more than one tree created with the Bootstrap method.

6. Random Forests(RF)

  ðŸ“Œ It is based on the evaluation of the predictions produced by multiple decision trees.

7. Gradient Boosting Machines(GBM)

  ðŸ“Œ It is a generalized version of AdaBoost that can be easily adapted to classification and regression problems. A series of models in the form of a single predictive model are constructed on the residuals.

8. Extreme Gradient Boosting(XGBoost)

  ðŸ“Œ XGBoost is optimized to increase the speed and prediction performance of GBM. It is scalable and can be integrated into different platforms.

9. LightGBM

  ðŸ“Œ LightGBM is another type of GBM developed to increase the training time performance of XGBoost.

10. Category Boosting(CatBoost)

  ðŸ“Œ It is another fast, successful type of GBM that can automatically deal with categorical variables.
